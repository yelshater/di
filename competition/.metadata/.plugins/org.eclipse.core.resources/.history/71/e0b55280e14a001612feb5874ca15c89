'''
Created on Jul 14, 2016

@author: yehia
'''

import numpy as np
import pandas as pd
from _functools import reduce
from sklearn.cluster import KMeans
from sklearn.preprocessing.data import StandardScaler



def isNight(x):
    if (x is not None):
        if x.hour >=18 and x.hour <= 24:
            return 1
    return 0

#01-12-2010 8:26
dateparse = lambda x: pd.datetime.strptime(x, '%d-%m-%Y %H:%M')

df = pd.read_csv("/home/yehia/workspace/python/competition/retail-clustering/dataset/sample.csv" , parse_dates=['InvoiceDate'],date_parser=dateparse)

df['trans_value'] = df.apply(lambda row: row['Quantity'] * row['UnitPrice'] , axis = 1)
countries_cat_to_bin_df = pd.get_dummies(df['Country'])
distinct_countries = countries_cat_to_bin_df.to_dict().keys()


df = pd.concat([df,countries_cat_to_bin_df], axis=1)

invoice_dates = pd.DatetimeIndex(df['InvoiceDate'])

df['weekday'] = invoice_dates.weekday
df['isWeekEnd'] = df['weekday'].apply(lambda x : 1 if (x == 6 or x==5) else 0) #Sunday or Saturday


invoice_hours = df['InvoiceDate'].apply(lambda x : isNight(x))
df['isNight'] = invoice_hours

customer_dataframes = []

df_by_customer = df.groupby(['CustomerID'],as_index=False)

df_med_basket_size = df_by_customer['Quantity'].median()
customer_dataframes.append(df_med_basket_size)

print (df_med_basket_size)

df_med_trans_value = df_by_customer['trans_value'].median()
print (df_med_trans_value)
print (type(df_med_trans_value))
customer_dataframes.append(df_med_trans_value)


for country in distinct_countries:
    customer_dataframes.append(df_by_customer[country].mean())

customer_dataframes.append(df_by_customer["StockCode"].count())
customer_dataframes.append(df_by_customer["isNight"].mean())
customer_dataframes.append(df_by_customer["isWeekEnd"].mean())


customer_final_df = reduce(lambda left,right: pd.merge(left,right,on='CustomerID'), customer_dataframes)


print (customer_final_df)


customer_final_df.to_clipboard()


np_dataset_array = customer_final_df.values
cust_ids = [int(x[0]) for x in np_dataset_array]
print ("cust_ids " , cust_ids)
features_values = np.array([x[1:] for x in np_dataset_array])
features_values = StandardScaler().fit_transform(features_values)
cluster_model = KMeans(n_clusters=2)
cluster_model.fit(features_values)
cust_id_label_dict = dict(zip(cluster_model.labels_,cust_ids)) #key is the label (instanceid) value is the original customerid
closest_centroids = cluster_model.predict(features_values)
print ("closest_centroids " ,closest_centroids)
print (cluster_model.labels_)
print ("here the map " , cust_id_label_dict)
    
#clusters = dict(zip(labels, cluster_model[1]))
#print (clusters['17850'])
#print df